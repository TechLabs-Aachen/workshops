{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from data.mnist import load_data, transform_data\n",
    "from os.path  import join\n",
    "base_path = './data/datasets'\n",
    "\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n",
    "x_train_display, y_train_display, x_test_display, y_test_display = load_data(base_path)\n",
    "\n",
    "#\n",
    "# Show some random training and test images \n",
    "#\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_train_display[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train_display[r]))    \n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test_display[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test_display[r]))    \n",
    "\n",
    "show_images(images_2_show, titles_2_show)\n",
    "x_train, y_train, x_test, y_test = transform_data(x_train_display, y_train_display, x_test_display, y_test_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out the appropriate dimensions for the MLP layer here!\n",
    "\n",
    "\n",
    "first_layer = 42 # TODO: Replace 42 with the appropriate value! \n",
    "last_layer = 42  # TODO: Replace 42 with the appropriate value!\n",
    "\n",
    "layers = [first_layer, 250, 100, last_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.linear import init_parameters\n",
    "from nn.functions import linear\n",
    "import numpy.random as rnd\n",
    "\n",
    "# Go Implement init_parameters in nn/linear.py \n",
    "random_state = rnd.RandomState(42)\n",
    "parameters = init_parameters(layers, random_state=random_state)\n",
    "\n",
    "# check if your shapes look correct\n",
    "for layer in parameters:\n",
    "    A, b = layer\n",
    "    print(\"A\", A.shape, \"b\", b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go implement linear in nn/functions.py\n",
    "x = x_train[1]# an image in the training set\n",
    "y = linear(x, parameters[0][0], parameters[0][1])\n",
    "print(y.shape) # this should be the same shape as the input for our second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from act.functions import relu\n",
    "\n",
    "# Now implement your model that makes the prediction on x!\n",
    "#  - it should take the parameters we initialized above and the input x\n",
    "#  - add a non-linear activations function e.g. relu after each linear transformation\n",
    "# return the output of the last layer\n",
    "\n",
    "def model(parameters, x):\n",
    "    # TODO: implement the model\n",
    "    return x\n",
    "\n",
    "y = model(parameters, x)\n",
    "print(y.shape) # this should be the same shape as the last layer\n",
    "print(y) # that will be our prediction, or will it? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go implement the celoss in loss/functions.py\n",
    "from loss.functions import celoss\n",
    "Y = y.reshape(1, -1) # we reshape because our CELoss function expects a 2D array (N, 10)\n",
    "Y_TRAIN = y_train[1].reshape(1, -1) # we reshape because our CELoss function expects a 2D array (N, 10)\n",
    "\n",
    "print(celoss(Y, Y_TRAIN)) # this should be a scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "from jax import jit, value_and_grad\n",
    "from jax.debug import print as dprint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# re-init parameters for a fresh start everytime we run the cell\n",
    "random_state = rnd.RandomState(42)\n",
    "parameters = init_parameters(layers, random_state=random_state)\n",
    "\n",
    "avg_loss = AverageMeter() # we will use this to keep track of our average loss\n",
    "avg_acc = AverageMeter() # we will use this to keep track of our average accuracy\n",
    "\n",
    "  \n",
    "def forward(parameters, x_batch, y_batch):\n",
    "    # TODO: implement the forward pass, the forward pass should return the loss here\n",
    "    return x_batch\n",
    "\n",
    "@jit\n",
    "def forward_backward(parameters, x_batch, y_batch):\n",
    "    # TODO: implement the backward pass with updates on the parameters\n",
    "    # First use value_and_grad calculate the loss and differentiate the gradients\n",
    "    # then build a new list of parameters using the gradients and the update rule\n",
    "    # return loss, new_parameters\n",
    "    return 0, []\n",
    "\n",
    "def accuracy(params, x_batch, y_batch):\n",
    "  # TODO: implement the accuracy function\n",
    "  # push the input through the model\n",
    "  # you can find the prediction by using jnp.argmax on the output of the model (also on the y_batch)\n",
    "  # the accuracy is the jnp.mean of all correct predictions (output == y_batch)\n",
    "  return \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    bar_train = tqdm(range(0, len(x_train), batch_size)) # a cool progressbar\n",
    "    for i in bar_train:\n",
    "        x_batch = x_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        # forward pass\n",
    "        loss, parameters = forward_backward(parameters, x_batch, y_batch)\n",
    "        avg_loss.update(loss, batch_size)\n",
    "        bar_train.set_description(f\"TRAIN LOSS:{avg_loss.avg}\")\n",
    "\n",
    "    bar_test = tqdm(range(0, len(x_test), batch_size))\n",
    "    for i in bar_test:\n",
    "        x_batch = x_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        # forward pass\n",
    "        acc = accuracy(parameters, x_batch, y_batch)\n",
    "        avg_acc.update(acc, batch_size)\n",
    "        bar_test.set_description(f\"TEST ACC:{avg_acc.avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the prediction\n",
    "\n",
    "def predict(params, x_batch):\n",
    "    # TODO: implement the prediction function here\n",
    "    # you should be able to do that from the accuracy function :)\n",
    "    return 0\n",
    "\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test_display[r])        \n",
    "    titles_2_show.append('prediction [' + str(r) + '] = ' + str(predict(parameters, x_test[r].reshape(1, -1))))    \n",
    "\n",
    "show_images(images_2_show, titles_2_show)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
